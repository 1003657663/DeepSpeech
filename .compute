#!/bin/bash

set -xe

num_bytes=4
bytes="${num_bytes}-bytes"

# srcdir=`pwd`/../src
# apt-get install -y build-essential cmake libboost-all-dev zlib1g-dev libbz2-dev liblzma-dev openjdk-8-jdk bash-completion unzip
# mkdir -p /tmp/tf
# pushd /tmp/tf
#   # Download and install bazel
#   curl -LO "https://github.com/bazelbuild/bazel/releases/download/0.19.2/bazel_0.19.2-linux-x86_64.deb"
#   dpkg -i bazel_*.deb
#   # Download tensorflow
#   git clone --depth 1 --branch r1.13 http://github.com/mozilla/tensorflow
#   pushd tensorflow
#     ln -s $srcdir/native_client .
#     # Configure and build generate_trie
#     export TF_NEED_CUDA=0
#     export TF_ENABLE_XLA=0
#     export TF_NEED_JEMALLOC=1
#     export TF_NEED_OPENCL_SYCL=0
#     export TF_NEED_MKL=0
#     export TF_NEED_VERBS=0
#     export TF_NEED_MPI=0
#     export TF_NEED_IGNITE=0
#     export TF_NEED_GDR=0
#     export TF_NEED_NGRAPH=0
#     export TF_DOWNLOAD_CLANG=0
#     export TF_SET_ANDROID_WORKSPACE=0
#     export TF_NEED_TENSORRT=0
#     export GCC_HOST_COMPILER_PATH=/usr/bin/gcc
#     ./configure
#     bazel build --config=monolithic -c opt --copt=-march=native --copt=-fvisibility=hidden //native_client:generate_trie
#   popd # tensorflow
# popd # /tmp/tf  
# gen_trie=/tmp/tf/tensorflow/bazel-bin/native_client/generate_trie
# mkdir ${USER_DIR}/utf8
# cp ${gen_trie} ${USER_DIR}/utf8/generate_trie
## GENERATE TRIE
# ${USER_DIR}/utf8/generate_trie unused_param_inlieuof_alphabet "/data/rw/home/en/lm.binary" "/data/rw/home/en/trie_utf8"

apt-get install -y python3-venv swig
python3 -m venv /tmp/venv
source /tmp/venv/bin/activate

pip install wheel
pip install -r <(grep -v tensorflow requirements.txt)
pip install tensorflow-gpu==1.13.1

echo "COMPILE AND INSTALL CTC DECODER"
pushd ../src/native_client/ctcdecode
  make clean
  make NUM_PROCESSES=`nproc`
  pip install dist/*.whl
popd

mkdir -p /dotdot/keep/summaries
    
data="${SHARED_DIR}/data"
CV="${data}/mozilla/CommonVoice/v2.0/en/clips"
fis="${data}/LDC/fisher"
swb="${data}/LDC/LDC97S62/swb"
lbs="${data}/OpenSLR/LibriSpeech/librivox"

       # --train_files "${fis}-train-${bytes}.csv","${swb}-train-${bytes}.csv","${lbs}-train-clean-100-${bytes}.csv","${lbs}-train-clean-360-${bytes}.csv","${lbs}-train-other-500-${bytes}.csv" \
       # --dev_files "${lbs}-dev-clean-${bytes}.csv","${lbs}-dev-other-${bytes}.csv"\


python -u DeepSpeech.py \
       --train_files "${lbs}-train-clean-100-${bytes}.csv" \
       --dev_files "${lbs}-dev-clean-${bytes}.csv"\
       --test_files "${lbs}-test-clean-${bytes}.csv" \
       --lm_binary_path "/data/rw/home/en/lm-${bytes}.binary" \
       --lm_trie_path "/data/rw/home/en/trie_utf8-${bytes}" \
       --train_batch_size 24 \
       --dev_batch_size 48 \
       --test_batch_size 48 \
       --n_hidden 1024 \
       --learning_rate 0.0001 \
       --dropout_rate 0.2 \
       --epochs 100 \
       --noearly_stop \
       --checkpoint_dir "/dotdot/keep" \
       --summary_dir "/dotdot/keep/summaries"
